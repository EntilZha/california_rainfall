{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National Center for Atmospheric Research\n",
    "## 2017 Climate Informatics Hackathon: California Seasonal Rainfall Prediction Starting Kit\n",
    "Authors: David John Gagne II, Balazs Kegel, Andy Rhines\n",
    "\n",
    "## Introduction\n",
    "<img src=\"Oroville_dam_spillway_2017-02-11.jpg\" width=\"600px\">\n",
    "_Water flowing over the damaged Oroville Dam Spillway. Image source:_ [William Croyle, California Department of Water Resources](https://commons.wikimedia.org/wiki/File:Oroville_dam_spillway_2017-02-11.jpg)\n",
    "\n",
    "The state of California receives most of its annual rainfall during the winter months when storms fueled by moisture from the tropical Pacific impact the state. This past winter was the wettest on record for northern California, resulting in massive floods and over 1 billion dollars in damage. Storm runoff into Lake Oroville led to extensive releases of water along the Oroville Dam spillway. The main spillway was damaged during the releases but continued to be used due to the high volume of water. The emergency spillway then had to be used, which prompted fears of containment failure and led to large evacuations downstream of the dam. The cost to repair the spillway is estimated at 400 million dollars.\n",
    "\n",
    "Some of the flooding problems associated with dams in northern California could be managed better with more accurate seasonal and subseasonal forecasts of rainfall. If water managers had a skilled forecast of expected rainfall, then they could change the distribution of water in northern California to be more resilient to large rainfall events. The mitigation process can take weeks to complete, so seasonal forecast leadtimes are needed for effective mitigation. Current operational seasonal precipitation guidance from the NOAA Climate Prediction Center has no skill above climatology for northern California and is not presented in a way that is useful for water managers at the California Department of Water Resources. Current seasonal precipitation forecasting relies primarilly on teleconnection indices, such as ENSO. However, these indices individually are poorly correlated with northern California winter rainfall. For example, the \"Godzilla\" El Nino of 2015-2016 was expected to bring very heavy rain to California but no extreme rains appeared in the winter of 2015-16. Last years heavy rains happened when ENSO was closer to a neutral state. Other teleconnections should also have some correlation with California rainfall, but finding the most important connections and how they interact is not a task that can be easily done manually.\n",
    "\n",
    "The goal for the 2017 Climate Informatics Hackathon is to use the November-averaged atmospheric fields to predict the probability of at least 750 mm of rain in northern California between December and February. The observational record for northern California rainfall only goes back to the early 1920s, which would provide a very limited sample size for machine learning or statistical models. Therefore, we are going to use climate model output from simulations run over the last 1000 years. By using climate model output, we hope to sample better the range of possible combinations of weather patterns and rainfall and fit more complex ML and statistical models.\n",
    "\n",
    "## NCAR Last Millennium Ensemble\n",
    "The [NCAR Last Millennium Ensemble](http://www.cesm.ucar.edu/projects/community-projects/LME/) is a set of CESM climate model runs starting in 850 AD and run through 2005. The 850 to 1850 period covers preindustrial conditions and 1850-2005 covers the industrial era. This hackathon uses the 12 full forcing ensemble members, which use the same forcings but had their initial air temperature fields perturbed by a small random roundoff of $10^{-14}$C. The ensemble members thus capture the internal variability within the model's climate system. More information about the Last Millennium Ensemble can be found in its [BAMS paper](http://www.cesm.ucar.edu/projects/community-projects/LME/publications/Otto-Bliesner_BAMS-LME_2016-2.pdf).\n",
    "\n",
    "## The Data\n",
    "* TS: temperature at the surface (K)\n",
    "* PSL: mean sea level pressure (Pa) (not Pumpkin Spice Lattes!)\n",
    "* TMQ: precipitable water (mm)\n",
    "* U_500: west-east component of the wind at the 500 mb pressure level (m/s)\n",
    "* V_500: south-north component of the wind at the 500 mb pressure level (m/s)\n",
    "* Z3_500: geopotential height of the 500 mb pressure level (m)\n",
    "\n",
    "## Requirements\n",
    "The Anaconda or Miniconda Python distributions are recommended for downloading the dependencies for this hackathon. Python 3.5 or greater is highly recommended. The following libraries are required. \n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "* xarray\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* cartopy\n",
    "\n",
    "Once Anaconda or Miniconda is installed on your local machine, execute the following command to create a conda environment with all of the required libraries. \n",
    "```bash\n",
    "cd ~/ramp_kits/california_rainfall/\n",
    "conda env create -f environment.yml\n",
    "source activate ramp_ci_2017\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import cartopy.crs as ccrs\n",
    "from ipywidgets import interact, SelectionSlider\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Each variable is stored in a separate netCDF file. The data loading function is below. If your laptop does not have a large amount of RAM (< 4 GB), we highly recommend loading a smaller subset of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit this list of variables to load in a smaller subset.\n",
    "data_vars = [\"TS\", \"PSL\", \"TMQ\", \"U_500\", \"V_500\"]\n",
    "\n",
    "def read_data(path, f_prefix, data_vars):\n",
    "    X_coll = []\n",
    "    for data_var in data_vars:\n",
    "        nc_file = join(path, \"data\", f_prefix + \"_{0}.nc\".format(data_var))\n",
    "        print(nc_file)\n",
    "        ds = xr.open_dataset(nc_file, decode_times=False)\n",
    "        ds.load()\n",
    "        X_coll.append(ds[data_var].stack(enstime=(\"ens\", \"time\")).transpose(\"enstime\", \"lat\", \"lon\"))\n",
    "        ds.close()\n",
    "    X_ds = xr.merge(X_coll)\n",
    "    y = pd.read_csv(join(path, \"data\", f_prefix + \"_precip_90.csv\"), index_col=\"Year\")\n",
    "    y_array = np.concatenate([y[c] for c in y.columns])\n",
    "    return X_ds, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train_TS.nc\n",
      "./data/train_PSL.nc\n",
      "./data/train_TMQ.nc\n",
      "./data/train_U_500.nc\n",
      "./data/train_V_500.nc\n",
      "./data/train_Z3_500.nc\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = read_data(\"./\", \"train\", data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 144)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[\"TS\"].sel(ens=0, time=334.0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Data\n",
    "The training data fields are viewable with this interactive widget. Check out the amount of variability among ensemble members and how different fields are linked with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fbe4f494e047899e8f98c0943166eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_grid>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.arange(850, 2005)\n",
    "def plot_grid(ens, year, var):\n",
    "    ti = np.where(year == years)[0][0]\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    min_val = train_X[var].min()\n",
    "    max_val = train_X[var].max()\n",
    "    cont = ax.contourf(train_X[\"lon\"] - 180, train_X[\"lat\"], \n",
    "                       train_X[var].sel(ens=ens, time=train_X[\"time\"].values[ti]),\n",
    "                       np.linspace(min_val, max_val, 20))\n",
    "    ax.set_title(var + \" \" + \"Year: {0:d} Member {1}\".format(year, ens))\n",
    "    plt.colorbar(cont)\n",
    "interact(plot_grid, ens=[0, 1, 2, 3], year=SelectionSlider(options=years.tolist()), \n",
    "         var=[\"TS\", \"PSL\", \"TMQ\", \"U_500\", \"V_500\", \"Z3_500\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Standardized Anomalies\n",
    "Seasonal signals in spatial data may be hidden by local variability. The polar regions have larger amounts of temperature variability than the tropics, for example. Machine learning and statistical models may focus on local variability instead of spatial variability if the local variability is not controlled for. One way to do this is to normalize the data based on the temporal mean and standard deviation at each grid point. The code for this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_anomalies = xr.merge([(train_X[var] - train_X[var].mean(axis=0)) / (train_X[var].std(axis=0)) for var in data_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wave patterns and dipoles across the globe are now far more obvious in the standardized anomaly data than they were in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbcaf891ec24e9aa8ccf55ee4fed80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_anomaly>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_anomaly(ens, year, var):\n",
    "    ti = np.where(year == years)[0][0]\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    ax.coastlines()\n",
    "    min_val = -5\n",
    "    max_val = 5\n",
    "    cont = ax.contourf(train_X_anomalies[\"lon\"] - 180, train_X_anomalies[\"lat\"], \n",
    "                       train_X_anomalies[var].sel(ens=ens, time=train_X_anomalies[\"time\"].values[ti]),\n",
    "                       np.linspace(min_val, max_val, 11), cmap=\"RdBu_r\")\n",
    "    ax.set_title(var + \" \" + \"Year: {0:d} Member {1}\".format(year, ens))\n",
    "    plt.colorbar(cont)\n",
    "interact(plot_anomaly, ens=[0, 1, 2, 3], year=SelectionSlider(options=years.tolist()), \n",
    "         var=[\"TS\", \"PSL\", \"TMQ\", \"U_500\", \"V_500\", \"Z3_500\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "For this contest, the cross-validation will take advantage of the relative independence of the different ensemble members. The cross-validation object trains on data from the 3 training ensemble members and tests on the fourth. A separate public testing dataset consists of 4 other ensemble members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline\n",
    "The machine learning pipeline for this constest consists of two components: the feature extractor and the classifier. The feature extractor transforms the spatial fields into a flat table that can be processed by scikit-learn-style machine learning and statistical models. The classifier predicts the probability of 750 mm or greater DJF rainfall. \n",
    "\n",
    "The starting kit feature extractor spatially normalizes the data and the performs Prinicpal Component Analysis on each variable, keeping the top 20 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.sds = {}\n",
    "        # Set which model variables you want to use\n",
    "        self.variables = [\"TS\", \"PSL\", \"TMQ\"]\n",
    "        self.pca = {}\n",
    "        self.num_comps = 20\n",
    "\n",
    "    def fit(self, X_ds, y): \n",
    "        # Store the mean and standard deviation for each variable\n",
    "        for var in self.variables:\n",
    "            if var not in self.means.keys():\n",
    "                self.means[var] = X_ds[var].mean(axis=0).values\n",
    "                self.sds[var] = X_ds[var].std(axis=0).values\n",
    "                self.sds[var][self.sds[var] == 0] = 1 \n",
    "            # Normalize the data\n",
    "            var_norm = (X_ds[var] - self.means[var]) / self.sds[var]\n",
    "            # Combine the latitude and longitude dimensions into a flat array\n",
    "            var_flat = var_norm.stack(latlon=(\"lat\", \"lon\")).values\n",
    "            var_flat[np.isnan(var_flat)] = 0 \n",
    "            # Create and fit the PCA\n",
    "            self.pca[var] = PCA(n_components=self.num_comps)\n",
    "            self.pca[var].fit(var_flat)\n",
    "\n",
    "\n",
    "    def transform(self, X_ds):\n",
    "        X = np.zeros((np.prod(X_ds[self.variables[0]].shape[:1]), \n",
    "                      self.num_comps * len(self.variables)), dtype=np.float32)\n",
    "        c = 0 \n",
    "        for var in self.variables:\n",
    "            # Normalize each variable\n",
    "            var_norm = (X_ds[var] - self.means[var]) / self.sds[var]\n",
    "            var_flat = var_norm.stack(latlon=(\"lat\", \"lon\")).values\n",
    "            var_flat[np.isnan(var_flat)] = 0 \n",
    "            # Transform the data into princpal components and add to flat 2D array\n",
    "            X[:, c:c+self.num_comps] = self.pca[var].transform(var_flat)\n",
    "            c += self.num_comps\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier applies a logistic regression with L1 (LASSO) regularization to the principal component data. L1 regularization results in sparse coeffients, which means that most coefficients will be set to 0. It is a way to perform implicit feature selection with a linear model without having to evaluate a large combination of input variables as in stepwise forward selection. The C parameter controls the strength of the regularization. A smaller value results in fewer non-zero coefficients while a large value leads to more non-zero coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = LogisticRegression(C=0.01, penalty=\"l1\")\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing California Winter Extreme Rainfall Prediction\n",
      "Reading train and test files from ./data ...\n",
      "./data/train_TS.nc\n",
      "./data/train_PSL.nc\n",
      "./data/train_TMQ.nc\n",
      "./data/train_U_500.nc\n",
      "./data/train_V_500.nc\n",
      "./data/test_TS.nc\n",
      "./data/test_PSL.nc\n",
      "./data/test_TMQ.nc\n",
      "./data/test_U_500.nc\n",
      "./data/test_V_500.nc\n",
      "./data/train_TS.nc\n",
      "./data/train_PSL.nc\n",
      "./data/train_TMQ.nc\n",
      "./data/train_U_500.nc\n",
      "./data/train_V_500.nc\n",
      "Reading cv ...\n",
      "Training ./submissions/starting_kit ...\n",
      "CV fold 0\n",
      "\ttrain auc = 0.813\n",
      "\tvalid auc = 0.808\n",
      "\ttest auc = 0.783\n",
      "\ttrain brier_score = 0.08\n",
      "\tvalid brier_score = 0.093\n",
      "\ttest brier_score = 0.077\n",
      "\ttrain brier_skill_score = 0.158\n",
      "\tvalid brier_skill_score = 0.15\n",
      "\ttest brier_skill_score = 0.112\n",
      "/Users/dgagne/anaconda3/envs/ramp/lib/python3.6/site-packages/ramp_workflow-0.1.dev0-py3.6.egg/rampwf/score_types/brier_score.py:99: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos_obs_rel_freq = pos_obs_freq / fore_freq\n",
      "\ttrain brier_score_reliability = 0.026\n",
      "\tvalid brier_score_reliability = 0.032\n",
      "\ttest brier_score_reliability = 0.02\n",
      "/Users/dgagne/anaconda3/envs/ramp/lib/python3.6/site-packages/ramp_workflow-0.1.dev0-py3.6.egg/rampwf/score_types/brier_score.py:140: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos_obs_rel_freq = pos_obs_freq / fore_freq\n",
      "\ttrain brier_score_resolution = 0.168\n",
      "\tvalid brier_score_resolution = 0.161\n",
      "\ttest brier_score_resolution = 0.138\n",
      "CV fold 1\n",
      "\ttrain auc = 0.82\n",
      "\tvalid auc = 0.783\n",
      "\ttest auc = 0.783\n",
      "\ttrain brier_score = 0.083\n",
      "\tvalid brier_score = 0.082\n",
      "\ttest brier_score = 0.078\n",
      "\ttrain brier_skill_score = 0.168\n",
      "\tvalid brier_skill_score = 0.124\n",
      "\ttest brier_skill_score = 0.103\n",
      "\ttrain brier_score_reliability = 0.029\n",
      "\tvalid brier_score_reliability = 0.023\n",
      "\ttest brier_score_reliability = 0.02\n",
      "\ttrain brier_score_resolution = 0.172\n",
      "\tvalid brier_score_resolution = 0.141\n",
      "\ttest brier_score_resolution = 0.129\n",
      "CV fold 2\n",
      "\ttrain auc = 0.822\n",
      "\tvalid auc = 0.776\n",
      "\ttest auc = 0.78\n",
      "\ttrain brier_score = 0.082\n",
      "\tvalid brier_score = 0.086\n",
      "\ttest brier_score = 0.078\n",
      "\ttrain brier_skill_score = 0.177\n",
      "\tvalid brier_skill_score = 0.099\n",
      "\ttest brier_skill_score = 0.1\n",
      "\ttrain brier_score_reliability = 0.031\n",
      "\tvalid brier_score_reliability = 0.023\n",
      "\ttest brier_score_reliability = 0.019\n",
      "\ttrain brier_score_resolution = 0.191\n",
      "\tvalid brier_score_resolution = 0.132\n",
      "\ttest brier_score_resolution = 0.128\n",
      "CV fold 3\n",
      "\ttrain auc = 0.815\n",
      "\tvalid auc = 0.797\n",
      "\ttest auc = 0.785\n",
      "\ttrain brier_score = 0.083\n",
      "\tvalid brier_score = 0.083\n",
      "\ttest brier_score = 0.078\n",
      "\ttrain brier_skill_score = 0.164\n",
      "\tvalid brier_skill_score = 0.14\n",
      "\ttest brier_skill_score = 0.102\n",
      "\ttrain brier_score_reliability = 0.029\n",
      "\tvalid brier_score_reliability = 0.026\n",
      "\ttest brier_score_reliability = 0.019\n",
      "\ttrain brier_score_resolution = 0.172\n",
      "\tvalid brier_score_resolution = 0.162\n",
      "\ttest brier_score_resolution = 0.126\n",
      "----------------------------\n",
      "train auc = 0.818 ± 0.0039\n",
      "train brier_score = 0.082 ± 0.0013\n",
      "train brier_skill_score = 0.167 ± 0.007\n",
      "train brier_score_reliability = 0.029 ± 0.0015\n",
      "train brier_score_resolution = 0.176 ± 0.0089\n",
      "valid auc = 0.791 ± 0.0126\n",
      "valid brier_score = 0.086 ± 0.0042\n",
      "valid brier_skill_score = 0.128 ± 0.0191\n",
      "valid brier_score_reliability = 0.026 ± 0.0036\n",
      "valid brier_score_resolution = 0.149 ± 0.0126\n",
      "test auc = 0.783 ± 0.0017\n",
      "test brier_score = 0.078 ± 0.0004\n",
      "test brier_skill_score = 0.104 ± 0.0048\n",
      "test brier_score_reliability = 0.02 ± 0.0004\n",
      "test brier_score_resolution = 0.13 ± 0.0046\n"
     ]
    }
   ],
   "source": [
    "!source activate ramp; ramp_test_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submitting to [ramp.studio](http://ramp.studio)\n",
    "\n",
    "Once you found a good model, you can submit it to [ramp.studio](http://www.ramp.studio). First, if it is your first time using RAMP, [sign up](http://www.ramp.studio/sign_up), otherwise [log in](http://www.ramp.studio/login). Then find an open event on the particular problem, for example, the event [california_rainfall](https://www.ramp.studio/events/california_rainfall) for this RAMP. Sign up for the event. Both signups are controled by RAMP administrators, so there **can be a delay between asking for signup and being able to submit**.\n",
    "\n",
    "Once your signup request is accepted, you can go to your [sandbox](http://www.ramp.studio/events/california_rainfall/sandbox) and copy-paste (or upload) [`ts_feature_extractor.py`](/edit/submissions/starting_kit/ts_feature_extractor.py) and [`regressor.py`](/edit/submissions/starting_kit/regressor.py) from `submissions/starting_kit`. Save it, rename it, then submit it. The submission is trained and tested on our backend in the same way as `ramp_test_submission` does it locally. While your submission is waiting in the queue and being trained, you can find it in the \"New submissions (pending training)\" table in [my submissions](http://www.ramp.studio/events/california_rainfall/my_submissions). Once it is trained, you get a mail, and your submission shows up on the [public leaderboard](http://www.ramp.studio/events/california_rainfall/leaderboard). \n",
    "If there is an error (despite having tested your submission locally with `ramp_test_submission`), it will show up in the \"Failed submissions\" table in [my submissions](http://www.ramp.studio/events/california_rainfall/my_submissions). You can click on the error to see part of the trace.\n",
    "\n",
    "After submission, do not forget to give credits to the previous submissions you reused or integrated into your submission.\n",
    "\n",
    "The data set we use at the backend is usually different from what you find in the starting kit, so the score may be different.\n",
    "\n",
    "The usual way to work with RAMP is to explore solutions, add feature transformations, select models, perhaps do some AutoML/hyperopt, etc., _locally_, and checking them with `ramp_test_submission`. The script prints mean cross-validation scores \n",
    "```\n",
    "----------------------------\n",
    "train rmse = 0.896 ± 0.0093\n",
    "valid rmse = 0.799 ± 0.0675\n",
    "test rmse = 0.97 ± 0.0115\n",
    "```\n",
    "The official score in this RAMP (the first score column after \"historical contributivity\" on the [leaderboard](http://www.ramp.studio/events/california_rainfall/leaderboard)) is root mean squared error (\"rmse\"), so the line that is relevant in the output of `ramp_test_submission` is `valid rmse = 0.799 ± 0.0675`. When the score is good enough, you can submit it at the RAMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ramp]",
   "language": "python",
   "name": "conda-env-ramp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
